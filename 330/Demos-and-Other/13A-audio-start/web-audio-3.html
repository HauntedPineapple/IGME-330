<!DOCTYPE html>
<html lang="en">

<head>
	<meta charset="utf-8" />
	<title>Web Audio 3</title>
	<style>
		canvas {
			border: 1px solid black;
			display: block;
			margin: 10px;
		}

		* {
			font-family: sans-serif;
		}

		span {
			margin-right: 2em;
		}

		#slider-distortion {
			position: relative;
			top: .7em;
		}

		#controls {
			user-select: none;
			margin: 10px 0px 15px 5px;
		}
	</style>
</head>

<body>
	<div id="controls">
		<span><label for="cb-highshelf">Highshelf Filter (Treble)</label><input type="checkbox"
				id="cb-highshelf"></span>
		<span><label for="cb-lowshelf">Lowshelf Filter (Bass)</label><input type="checkbox" id="cb-lowshelf"></span>
		<span><label for="cb-distortion">Distortion</label><input type="checkbox" id="cb-distortion"></span>
		<span>0 <input type="range" min="0" max="100" value="0" id="slider-distortion"> 100</span>
	</div>

	<canvas width="640" height="480"></canvas>

	<!-- use obama-oilspill.mp3 or human-voice.mp3 -->
	<audio controls src="sounds/obama-oilspill.mp3"></audio>

	<p>Choose a sound file from your hard drive! -->
		<input id="upload" title="Upload File" type="file" accept="audio/*">
	</p>


	<script>
		const NUM_SAMPLES = 128;
		// 1 - get reference to <audio> element on page
		let audioElement = document.querySelector('audio');

		// 2 - create a new `AudioContext` object
		// https://developer.mozilla.org/en-US/docs/Web/API/AudioContext
		let audioCtx = new (window.AudioContext || window.webkitAudioContext); // to support Safari and mobile

		// 3 - create a node that points at the <audio> element
		// https://developer.mozilla.org/en-US/docs/Web/API/AudioContext/createMediaElementSource
		let sourceNode = audioCtx.createMediaElementSource(audioElement);

		// 4 - create a *analyser node*
		// https://developer.mozilla.org/en-US/docs/Web/API/AnalyserNode
		// this gets us real-time frequency and time-domain (i.e. waveform) information
		let analyserNode = audioCtx.createAnalyser();

		// 5 - How many samples do we want? fft stands for Fast Fourier Transform
		analyserNode.fftSize = NUM_SAMPLES;

		let highshelfBiquadFilter = audioCtx.createBiquadFilter();
		highshelfBiquadFilter.type = "highshelf";
		let lowshelfBiquadFilter = audioCtx.createBiquadFilter();
		lowshelfBiquadFilter.type = "lowshelf";
		let distortionFilter = audioCtx.createWaveShaper();

		// 6 - hook up the <audio> element to the analyserNode
		sourceNode.connect(highshelfBiquadFilter);
		highshelfBiquadFilter.connect(lowshelfBiquadFilter);
		lowshelfBiquadFilter.connect(distortionFilter);
		distortionFilter.connect(analyserNode);

		// 7 - connect to the destination i.e. the speakers
		analyserNode.connect(audioCtx.destination);

		// 8 - create a new array of 8-bit integers (0-255)
		// https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Uint8Array
		let data = new Uint8Array(analyserNode.frequencyBinCount); // OR analyserNode.fftSize/2

		// Chrome autoplay fix
		// https://developers.google.com/web/updates/2017/09/autoplay-policy-changes
		document.querySelector("audio").onplay = (e) => {
			if (audioCtx.state == "suspended") {
				audioCtx.resume();
			}
		};

		// canvas stuff
		let ctx = document.querySelector("canvas").getContext("2d");
		const BAR_WIDTH = 10;
		const MAX_BAR_HEIGHT = 200;
		const PADDING = 2;
		const MIDDLE_Y = ctx.canvas.height - 20;

		function loop() {
			// 9 - this schedules a call to the loop() method in 1/60 second
			requestAnimationFrame(loop);

			// 10 - populate the array with the frequency data
			// notice these arrays are passed *by reference*
			analyserNode.getByteFrequencyData(data);

			// 11 - Let's visualize the audio data on the canvas
			ctx.clearRect(0, 0, ctx.canvas.width, ctx.canvas.height);
			ctx.save();
			ctx.fillStyle = "red";
			ctx.translate(0, MIDDLE_Y);
			for (let b of data) {
				let percent = b / 255;
				percent = percent < 0.02 ? .02 : percent;
				ctx.translate(BAR_WIDTH, 0);
				ctx.save();
				ctx.scale(1, -1);
				ctx.fillRect(0, 0, BAR_WIDTH, MAX_BAR_HEIGHT * percent);
				ctx.restore();
				ctx.translate(PADDING, 0);
			}
			ctx.restore();

		}

		let highshelf = lowshelf = distortion = false;
		let distortionAmount = 20;

		function setupUI() {
			// set the initial state of the high shelf checkbox
			document.querySelector('#cb-highshelf').checked = highshelf;
			// change the value of `highshelf` every time the high shelf checkbox changes state
			document.querySelector('#cb-highshelf').onchange = e => {
				highshelf = e.target.checked;
				toggleHighshelf(); // turn on or turn off the filter, depending on the value of `highshelf`!
			};
			toggleHighshelf(); // when the app starts up, turn on or turn off the filter, depending on the value of `highshelf`!

			document.querySelector('#cb-lowshelf').checked = lowshelf;
			document.querySelector('#cb-lowshelf').onchange = e => {
				lowshelf = e.target.checked;
				toggleLowshelf();
			};
			toggleLowshelf();

			document.querySelector('#cb-distortion').checked = distortion;
			document.querySelector('#cb-distortion').onchange = e => {
				distortion = e.target.checked;
				toggleDistortion();
			};
			toggleDistortion();
			document.querySelector('#slider-distortion').value = distortionAmount;
			document.querySelector('#slider-distortion').onchange = e => {
				distortionAmount = Number(e.target.value);
				toggleDistortion();
			};
		}

		function toggleHighshelf() {
			if (highshelf) {
				highshelfBiquadFilter.frequency.setValueAtTime(1000, audioCtx.currentTime); // we created the `biquadFilter` (i.e. "treble") node last time
				highshelfBiquadFilter.gain.setValueAtTime(25, audioCtx.currentTime);
			} else {
				highshelfBiquadFilter.gain.setValueAtTime(0, audioCtx.currentTime);
			}
		}

		function toggleLowshelf() {
			if (lowshelf) {
				lowshelfBiquadFilter.frequency.setValueAtTime(1000, audioCtx.currentTime);
				lowshelfBiquadFilter.gain.setValueAtTime(15, audioCtx.currentTime);
			} else {
				lowshelfBiquadFilter.gain.setValueAtTime(0, audioCtx.currentTime);
			}
		}

		function toggleDistortion() {
			if (distortion) {
				distortionFilter.curve = null; // being paranoid and trying to trigger garbage collection
				distortionFilter.curve = makeDistortionCurve(distortionAmount);
			} else {
				distortionFilter.curve = null;
			}
		}

		// from: https://developer.mozilla.org/en-US/docs/Web/API/WaveShaperNode
		function makeDistortionCurve(amount = 20) {
			let n_samples = 256, curve = new Float32Array(n_samples);
			for (let i = 0; i < n_samples; ++i) {
				let x = i * 2 / n_samples - 1;
				curve[i] = (Math.PI + amount) * x / (Math.PI + amount * Math.abs(x));
				// https://stackoverflow.com/questions/22312841/waveshaper-node-in-webaudio-how-to-emulate-distortion
			}
			/* Here are some other equations you can try (one at a time) - also try visualizing them using the - http://kevincennis.github.io/transfergraph/ - tool:
			curve[i] = x; // does not modify sound
			curve[i] = 0; // silence
			curve[i] = x * amount; // classic distortion
			curve[i] = (Math.PI + amount) * x / (Math.PI + amount * Math.abs(x));
			curve[i] = (Math.PI + 100 * x / 2) / (Math.PI + 100 * Math.abs(x)); // nice distortion
			curve[i] = -(Math.PI + 100 * x / 2) / (Math.PI + 50 * Math.abs(x));
			curve[i] = Math.random() * 2 - 1;	// static!	
			curve[i] = x * 5 + Math.random() * 2 - 1; // adds a less intrusive static to the audio
			curve[i] = x * Math.sin(x) * amount / 5; // sounds like a cross between Donald Duck and Cartman from South Park
			(3 + 20) * x * 57 * (Math.PI / 180) / (Math.PI + 20 * Math.abs(x)) // from the stack overflow post
			*/
			return curve;
		}

		document.querySelector("#upload").onchange = (e) => {
			const files = e.target.files;
			document.querySelector("audio").src = URL.createObjectURL(files[0]);
		};

		setupUI();
		loop();
	</script>
</body>

</html>